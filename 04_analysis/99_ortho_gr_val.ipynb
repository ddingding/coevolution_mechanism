{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidding/anaconda3/envs/tf_env/lib/python3.7/site-packages/statsmodels/compat/pandas.py:49: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  data_klasses = (pandas.Series, pandas.DataFrame, pandas.Panel)\n",
      "/Users/davidding/anaconda3/envs/tf_env/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "/Users/davidding/anaconda3/envs/tf_env/lib/python3.7/site-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import plottingTools as pt\n",
    "from plottingTools import sample_to_8wells, sample_to_7wells, blank_wells\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from matplotlib import cm, gridspec\n",
    "\n",
    "avb_cols = {'pur':'#5B49B6', \n",
    "            'blu':'#52A4D9', \n",
    "            'tur':'#59C09D',\n",
    "            'tea':'#B3EBAD',\n",
    "            'yel': '#C3D64C',\n",
    "            'gra':'#9B9B9D'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('/Users/davidding/PycharmProjects/pareSingleLibrary2/codebase/src/paper_style1.mplstyle')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of nontoxic mutants in all concentrations 839\n",
      "# of toxin mutants that are toxic in all conditions: 311\n",
      "# of nontoxic mutants in all concentrations 855\n",
      "# of toxin mutants that are toxic in all conditions: 781\n",
      "len of mt_toxins: 310\n",
      "len of ta_toxins 781\n",
      "15\n",
      "15\n",
      "30\n",
      "37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2012_load_data.py:636: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_muts_mt_wt_toxin['t_pos_pdb'] = df_muts_mt_wt_toxin.t_mut.str[1:-1].astype(int) +1\n",
      "2012_load_data.py:737: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_curr['at_mut'] = [at] * len(df_curr)\n"
     ]
    }
   ],
   "source": [
    "%run -i 2012_load_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "din = '/Users/davidding/Dropbox (HMS)/parESingleLibrary/ex58_evovlability_suprpessors/platereader/'\n",
    "dout = '/Users/davidding/PycharmProjects/pareSingleLibrary2/codebase/pairedEnd/ex58/fig5/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# combined growth rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n- currently: od-difference / od_difference range of +/- at\\n- \\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sample_wells = ['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9',\n",
    "       'A10', 'A11', 'A12', 'B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8',\n",
    "       'B9', 'B10', 'B11', 'B12', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7',\n",
    "       'C8', 'C9', 'C10', 'C11', 'C12', 'D1', 'D2', 'D3', 'D4', 'D5', 'D6',\n",
    "       'D7', 'D8', 'D9', 'D10', 'D11', 'D12', 'E1', 'E2', 'E3', 'E4', 'E5',\n",
    "       'E6', 'E7', 'E8', 'E9', 'E10', 'E11', 'E12', 'F1', 'F2', 'F3', 'F4',\n",
    "       'F5', 'F6', 'F7', 'F8', 'F9', 'F10', 'F11', 'F12', 'G1', 'G2', 'G3',\n",
    "       'G4', 'G5', 'G6', 'G7', 'G8', 'G9', 'G10', 'G11', 'G12', 'H1', 'H2',\n",
    "       'H3', 'H4', 'H5', 'H6', 'H7', 'H8', 'H9', 'H10', 'H11', 'H12']\n",
    "# adds a continuous number of hours\n",
    "def date_str_to_mins(date_str):\n",
    "    # expects '0:14:10'\n",
    "    hh, mm, ss = date_str.split(':')\n",
    "    return float(hh) + (float(mm)+1)/60\n",
    "    #date_str_to_mins('0:14:10')\n",
    "    \n",
    "# plate 1 get gr between 5 and 12 hours.\n",
    "\n",
    "def get_gr(df_data1,sample_to_n , \n",
    "           sample_to_wells = sample_to_7wells, wells_exclude=[], \n",
    "           blank_wells=blank_wells, \n",
    "           sample_wells=sample_wells, \n",
    "           t1= 5, \n",
    "           t2=12,\n",
    "          subtract_od_ts = True, # subtract grs, or divide grs\n",
    "           use_log_od_diff = False\n",
    "          ):\n",
    "    \n",
    "    # subtracting the blank well OD from the measurement wells\n",
    "    blank = np.mean(df_data1[blank_wells], axis=1)\n",
    "    for c in sample_wells:\n",
    "        if c not in blank_wells:\n",
    "            df_data1[c+'_from_blank'] = df_data1[c] - blank\n",
    "            df_data1[c+'_from_blank_log'] = np.log(df_data1[c+'_from_blank']) \n",
    "\n",
    "    # add time in continuous hours\n",
    "    df_data1['t_hrs'] = df_data1.apply(lambda r: date_str_to_mins(r.Time), axis=1)\n",
    "    df_dat = df_data1.drop(columns='Time') # cannot convert to float\n",
    "    df_dat = df_dat.astype(float)\n",
    "    \n",
    "    # get the mean of the blank at both timepoints, and the stdeviations\n",
    "    #display(df_dat)\n",
    "    #test this\n",
    "    blank_mean_t1 = np.mean(np.matrix.flatten(df_dat.loc[df_dat.t_hrs ==t1][blank_wells].values))\n",
    "    blank_std_t1 = np.std(np.matrix.flatten(df_dat.loc[df_dat.t_hrs ==t1][blank_wells].values))\n",
    "    blank_mean_t2 = np.mean(np.matrix.flatten(df_dat.loc[df_dat.t_hrs ==t2][blank_wells].values))\n",
    "    blank_std_t2 = np.std(np.matrix.flatten(df_dat.loc[df_dat.t_hrs ==t2][blank_wells].values))\n",
    "    #print(blank_mean_t1, blank_std_t1)\n",
    "    \n",
    "    # for each sample, get the mean of the observcations, and the stdeviations at each time point\n",
    "    sample_to_v_t1_mean = {}\n",
    "    sample_to_v_t1_std = {}\n",
    "    sample_to_v_t2_mean = {}\n",
    "    sample_to_v_t2_std = {}\n",
    "    \n",
    "    for n, sample_n in sample_to_n.items():\n",
    "        # get wells of interest\n",
    "        wells = sample_to_wells[n]\n",
    "        #keep only wells that are not outliers\n",
    "        wells_keep = [well for well in wells if well not in wells_exclude]\n",
    "        ind_vals_t1 = df_dat.loc[df_dat.t_hrs == t1][wells_keep]\n",
    "        ind_vals_t2 = df_dat.loc[df_dat.t_hrs == t2][wells_keep]\n",
    "        \n",
    "        sample_to_v_t1_mean[sample_n] = np.mean(ind_vals_t1, axis=1).values[0]\n",
    "        sample_to_v_t2_mean[sample_n] = np.mean(ind_vals_t2, axis=1).values[0]\n",
    "        sample_to_v_t1_std[sample_n] = np.std(ind_vals_t1, axis=1).values[0]\n",
    "        sample_to_v_t2_std[sample_n] = np.std(ind_vals_t2, axis=1).values[0]\n",
    "        \n",
    "    err_list = [blank_mean_t1, blank_std_t1, \n",
    "                    blank_mean_t2, blank_std_t2, \n",
    "                    sample_to_v_t1_mean, sample_to_v_t1_std, \n",
    "                    sample_to_v_t2_mean, sample_to_v_t2_std\n",
    "                   ]\n",
    "    #print(sample_to_v_t1_mean, sample_to_v_t1_std)\n",
    "    # for each sample, calculate the sample_n to mean fold change\n",
    "    # first calculate fold-change\n",
    "    if subtract_od_ts:\n",
    "        # take the difference in OD between 2 timepoints\n",
    "        fold_ser = pd.DataFrame((df_dat.loc[df_dat.t_hrs ==t2].values - df_dat.loc[df_dat.t_hrs ==t1].values).reshape(1,-1),\n",
    "                           columns= df_dat.columns)\n",
    "    else:\n",
    "        fold_ser = pd.DataFrame((df_dat.loc[df_dat.t_hrs ==t2].values / df_dat.loc[df_dat.t_hrs ==t1].values).reshape(1,-1),\n",
    "                           columns= df_dat.columns)\n",
    "\n",
    "    # second get the mean across the fold change series for a particular sample\n",
    "    sample_n_to_fold_change = {}\n",
    "    for n, sample_n in sample_to_n.items():\n",
    "        # get wells of interest\n",
    "        wells = sample_to_wells[n]\n",
    "        #keep only wells that are not outliers\n",
    "        wells_keep = [well for well in wells if well not in wells_exclude]\n",
    "        # get the difference in wells for the ones that are different just the blank ones, not the log ones\n",
    "        if not use_log_od_diff:\n",
    "            wells_keep = [w+'_from_blank' for w in wells_keep]\n",
    "        else:\n",
    "            wells_keep = [w+'_from_blank_log' for w in wells_keep]\n",
    "        #from the fold-series, fetch the wells to keep\n",
    "        ind_traces = fold_ser[wells_keep]\n",
    "        # caclulate mean change in OD and return\n",
    "        mean_traces = np.mean(ind_traces, axis=1)\n",
    "        sample_n_to_fold_change[sample_n] =mean_traces.values[0]\n",
    "        \n",
    " \n",
    "    return sample_n_to_fold_change, err_list\n",
    "\n",
    "def norm_dic_linear(fch1):\n",
    "    #normalizes a dictionary by how much the growth rates fall linearly between the scale of the wt toxin + and - antitoxin\n",
    "    norm_fch1={}\n",
    "    for m,v in fch1.items():\n",
    "        if m not in ['wtT:wtAT', 'wtT:-AT']:\n",
    "            norm_v = (v-fch1['wtT:-AT'])/ (fch1['wtT:wtAT'] - fch1['wtT:-AT'])\n",
    "            norm_fch1[m] = norm_v\n",
    "    return norm_fch1\n",
    "\n",
    "def norm_dic_relative_wt(fch1):\n",
    "    #normalizes a dictionary by how much the growth rates fall linearly between the scale of the wt toxin + and - antitoxin\n",
    "    norm_fch1={}\n",
    "    for m,v in fch1.items():\n",
    "        if m not in ['wtT:wtAT']:\n",
    "            norm_v = v-fch1['wtT:wtAT'] # just calculate relative gr\n",
    "            norm_fch1[m] = norm_v\n",
    "    return norm_fch1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidding/anaconda3/envs/tf_env/lib/python3.7/site-packages/pandas/core/series.py:679: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_all_grs(t1=5, t2=12, subtract_od_ts=True, use_log_od_diff=False, use_linear_scale=True):\n",
    "    # get the grs for all the 210223 samples\n",
    "    sample_to_n_1 = {1: 'wtT:wtAT',#'wt_t_at_411', \n",
    "                    2: 'wtT:-AT',#'mcs_at_dds441', \n",
    "                    3: 'wtT:G62L',#'G62L+292', # from 292 cells\n",
    "                    4: 'wtT:W59T',#'W59T+292', # from 292 cells\n",
    "                    5: 'wtT:F73K',#'F73K+292',\n",
    "                    6: 'wtT:K63L',#'K63L+292',\n",
    "                    7: 'V5L:-AT'#'401(wtAT)+420(V5L)', # from 401 cells, so it's broken\n",
    "                  }\n",
    "    df_data1 = pd.read_csv(din + '210223_ortho_p1_data.csv')\n",
    "\n",
    "    fch1_old, err_list_1_old = get_gr(df_data1, sample_to_n = sample_to_n_1, \n",
    "                      t1=t1, t2=t2, \n",
    "                      subtract_od_ts=subtract_od_ts, \n",
    "                     use_log_od_diff=use_log_od_diff)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    sample_to_n_2 = {1: 'wtT:wtAT',#'wt_t_at_411', \n",
    "                    2: 'wtT:-AT',#'mcs_at_dds441', \n",
    "                    #3: 'A66F:-AT1',# see sample number 5 #'401(wtAT)+421(A66F)', # from 401 cells\n",
    "                    4: 'V5L:-AT',#'395(-AT)+420(V5L)', # from 395 cells\n",
    "                    5: 'A66F:-AT',#'395(-AT)+421(A66F)', # from 395 cells\n",
    "                    6: 'V5L:G62L',#'G62L+420 (V5L)', # from G62L new cryo1 cells\n",
    "                    7: 'V5L:W59T'#'W59T+420 (V5L)', # from W59T new cryo15 cells\n",
    "                  }\n",
    "    df_data2 = pd.read_csv(din + '210223_ortho_p2_data.csv')\n",
    "    fch2_old, err_list_2_old = get_gr(df_data2, sample_to_n = sample_to_n_2,\n",
    "                      t1=t1, t2=t2, \n",
    "                      subtract_od_ts=subtract_od_ts, \n",
    "                     use_log_od_diff=use_log_od_diff)\n",
    "\n",
    "\n",
    "    # 210414 orthogonal growth rates\n",
    "    sample_to_n_1 = {1: 'wtT:wtAT',#'wt_t_at_411', \n",
    "                    2: 'wtT:-AT',#'mcs_at_dds441', \n",
    "                    3: 'wtT:G62L',#'G62L+292', # from 292 cells\n",
    "                    4: 'wtT:W59T',#'W59T+292', # from 292 cells\n",
    "                    5: 'E37D:G62L',\n",
    "                    6: 'G81Y:G62L',\n",
    "                    7: 'P8A:G62L',\n",
    "                     8: 'R52L:G62L'\n",
    "                    }\n",
    "    df_data1 = pd.read_csv(din + '210414_p1_1200_g62l_data.csv')\n",
    "    fch1_new, err_list_1_new = get_gr(df_data1, sample_to_n = sample_to_n_1, \n",
    "                      sample_to_wells=sample_to_8wells, \n",
    "                      t1=t1, t2=t2, \n",
    "                      subtract_od_ts=subtract_od_ts, \n",
    "                     use_log_od_diff=use_log_od_diff)\n",
    "\n",
    "    sample_to_n_2 = {1: 'wtT:wtAT',#'wt_t_at_411', \n",
    "                    2: 'wtT:-AT',#'mcs_at_dds441', \n",
    "                    3: 'wtT:G62L',#'G62L+292', # from 292 cells\n",
    "                    4: 'wtT:W59T',#'W59T+292', # from 292 cells\n",
    "                    5: 'P8N:W59T',\n",
    "                    6: 'V75G:W59T',\n",
    "                    7: 'G94_:W59T',\n",
    "                     8: 'W85P:W59T'\n",
    "                    }\n",
    "    df_data2 = pd.read_csv(din + '210414_p2_1200_w59t_data.csv')\n",
    "    # coz some of these have stuff growing\n",
    "    blank_wells2 = [c for c in blank_wells if c not in ['A5', 'A6', 'A7']]\n",
    "\n",
    "    fch2_new, err_list_2_new = get_gr(df_data2, sample_to_n = sample_to_n_2, \n",
    "                      sample_to_wells=sample_to_8wells, \n",
    "                      blank_wells = blank_wells2, \n",
    "                      t1=t1, t2=t2, \n",
    "                      subtract_od_ts=subtract_od_ts, \n",
    "                     use_log_od_diff=use_log_od_diff)\n",
    "\n",
    "    if use_linear_scale:\n",
    "        norm_fch1_old = norm_dic_linear(fch1_old)\n",
    "        norm_fch2_old = norm_dic_linear(fch2_old)\n",
    "        # normalize fold change\n",
    "        norm_fch1_new = norm_dic_linear(fch1_new)\n",
    "        norm_fch2_new = norm_dic_linear(fch2_new)\n",
    "    else:\n",
    "        norm_fch1_old = norm_dic_relative_wt(fch1_old)\n",
    "        norm_fch2_old = norm_dic_relative_wt(fch2_old)\n",
    "        # normalize fold change\n",
    "        norm_fch1_new = norm_dic_relative_wt(fch1_new)\n",
    "        norm_fch2_new = norm_dic_relative_wt(fch2_new)\n",
    "        \n",
    "    #combine dics\n",
    "    norm_fch_all_old = norm_fch1_old\n",
    "    norm_fch_all_old.update(norm_fch2_old)\n",
    "    # combine growth rates\n",
    "    norm_fch_all_new = norm_fch1_new\n",
    "    norm_fch_all_new.update(norm_fch2_new)\n",
    "    norm_fch_all = norm_fch_all_new\n",
    "    norm_fch_all.update(norm_fch_all_old)\n",
    "\n",
    "    return norm_fch_all, err_list_1_old, err_list_2_old, err_list_1_new, err_list_2_new\n",
    "dic_fch, err_list_1_old, err_list_2_old, err_list_1_new, err_list_2_new  = get_all_grs(t1=2, t2=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wtT:G62L': 0.04511340934320033,\n",
       " 'wtT:W59T': 0.04513472197607554,\n",
       " 'E37D:G62L': 0.032774003962309645,\n",
       " 'G81Y:G62L': 0.04538767567463893,\n",
       " 'P8A:G62L': 0.028264585496983557,\n",
       " 'R52L:G62L': 0.049457702878495095,\n",
       " 'P8N:W59T': 0.0286008153378241,\n",
       " 'V75G:W59T': 0.04754183328489533,\n",
       " 'G94_:W59T': 0.05046061923117791,\n",
       " 'W85P:W59T': 0.04982622403869411,\n",
       " 'wtT:F73K': 0.05140355805146509,\n",
       " 'wtT:K63L': 0.05229518174895317,\n",
       " 'V5L:-AT': 0.02646750225415425,\n",
       " 'A66F:-AT': 0.018547765808518833,\n",
       " 'V5L:G62L': 0.06072917289619021,\n",
       " 'V5L:W59T': 0.06157716773967678}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prop_error_norm_fch(v_t2, v_t1, p_t2, p_t1, n_t2, n_t1,\n",
    "              s_v_t2, s_v_t1, s_p_t2, s_p_t1, s_n_t2, s_n_t1):\n",
    "    # calculates propagated errors assuming independence of variables using only 2 time points of growth rate measurement\n",
    "    # v stands for value of interest\n",
    "    # p stands for positive control growth rate\n",
    "    # n stand for negative control gr\n",
    "    \n",
    "    # gr_plot = (fold_change_v - fold_change_n)/ (fold_change_p - fold_change_n)\n",
    "    \n",
    "    # need values for \n",
    "    # standard deviations: s_v_t2, s_v_t1, s_p_t2, s_p_t1, s_n_t2, s_n_t1\n",
    "    # and values of: v_t2, v_t1, p_t2, p_t1, n_t2, n_t1\n",
    "    sums = (s_v_t2**2 + s_v_t1**2 + \n",
    "        (((v_t2 - v_t1 + n_t1) - (p_t2 - p_t1 + n_t1)) / ((p_t2 - p_t1 + n_t1) - n_t2)**2)**2 * s_n_t2**2 + # (d(gr)/d(nt2))**2 * (s_n_t2)**2 \n",
    "        (((p_t2 - p_t1 - n_t2) - (v_t2 - v_t1 - n_t2)) / ((p_t2 - p_t1 - n_t2) - n_t1)**2 )**2 * s_n_t1**2 + # d(gr)/d(nt1) * s_n_t1\n",
    "        (-(v_t2 - v_t1 - n_t2 + n_t1) / ((-p_t1- n_t2 + n_t1) + p_t2)**2)**2 * s_p_t2**2 +                   # d(gr)/d(p_t2) * s_p_t2\n",
    "        ((v_t2 - v_t1 - n_t2 + n_t1) / ((p_t2 - n_t2 + n_t1) + p_t1)**2)**2 * s_p_t1**2                     # d(gr)/d(p_t1) * s_p_t1\n",
    "           )\n",
    "    #print(sums)\n",
    "    std_gr = np.sqrt(sums)\n",
    "    return std_gr\n",
    "    \n",
    "def get_errors_muts(err_list):\n",
    "    blank_mean_t1, blank_std_t1, blank_mean_t2, blank_std_t2, sample_to_v_t1_mean, sample_to_v_t1_std, sample_to_v_t2_mean, sample_to_v_t2_std = err_list\n",
    "    \n",
    "    sample_n_to_std = {}\n",
    "    for sample_n in sample_to_v_t1_mean.keys():\n",
    "        if sample_n not in ['wtT:wtAT', 'wtT:-AT']:\n",
    "            v_t2 = sample_to_v_t2_mean[sample_n]  \n",
    "            v_t1 = sample_to_v_t1_mean[sample_n] \n",
    "            p_t2 = sample_to_v_t2_mean['wtT:wtAT'] \n",
    "            p_t1 = sample_to_v_t1_mean['wtT:wtAT'] \n",
    "            n_t2 = blank_mean_t2\n",
    "            n_t1 = blank_mean_t1\n",
    "            s_v_t2 = sample_to_v_t2_std[sample_n] \n",
    "            s_v_t1 = sample_to_v_t1_std[sample_n]\n",
    "            s_p_t2 = sample_to_v_t2_std['wtT:wtAT'] \n",
    "            s_p_t1 = sample_to_v_t1_std['wtT:wtAT']\n",
    "            s_n_t2 = blank_std_t2\n",
    "            s_n_t1 = blank_std_t1\n",
    "            std_fold = prop_error_norm_fch(v_t2, v_t1, p_t2, p_t1, n_t2, n_t1,\n",
    "              s_v_t2, s_v_t1, s_p_t2, s_p_t1, s_n_t2, s_n_t1)\n",
    "            sample_n_to_std[sample_n] = std_fold\n",
    "    \n",
    "    return sample_n_to_std\n",
    "\n",
    "#this gets the propagated errors in the fold change calculation\n",
    "\n",
    "sample_to_std_1_old = get_errors_muts(err_list_1_old)\n",
    "sample_to_std_2_old = get_errors_muts(err_list_2_old)\n",
    "sample_to_std_1_new = get_errors_muts(err_list_1_new) \n",
    "sample_to_std_2_new = get_errors_muts(err_list_2_new)\n",
    "\n",
    "#combine them\n",
    "sample_to_std_1_old.update(sample_to_std_2_old)\n",
    "sample_to_std_1_new.update(sample_to_std_2_new)\n",
    "\n",
    "sample_to_std_1_new.update(sample_to_std_1_old)\n",
    "sample_to_std_1_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in a file\n",
    "'''\n",
    "# \n",
    "need_ats = ['G62L', 'W59T', 'F73K', 'K63L']\n",
    "need_at_to_errs_tup ={}\n",
    "\n",
    "for at in need_ats:\n",
    "    print(at_to_f_l[at])\n",
    "\n",
    "for at in ['G62L', 'W59T', 'F73K', 'K63L']:\n",
    "    print(at)\n",
    "    bayes_mcs_dir_ex47 = '/Users/davidding/Dropbox (HMS)/parESingleLibrary/ex51_set_up_additional_mutants/illumina/data/bayes_o2_2009/raw/doubles_ex47_l/'\n",
    "    bayes_mcs_dir_ex51 = '/Users/davidding/Dropbox (HMS)/parESingleLibrary/ex51_set_up_additional_mutants/illumina/data/bayes_o2_2009/raw/doubles_ex51_l/'\n",
    "\n",
    "    if at != 'K63L':\n",
    "        df_fit_curr = pd.read_csv(bayes_mcs_dir_ex47 + 'df_sm_bhs_diff_w_aa_m_178_'+at+'.csv')\n",
    "    else:\n",
    "        df_fit_curr = pd.read_csv(bayes_mcs_dir_ex51 + 'df_sm_bhs_diff_w_aa_m_178_'+at+'.csv')\n",
    "    \n",
    "    # need to correct for log2 scaling\n",
    "    samples = df_fit_curr['w_aa']/np.log(2)\n",
    "    pickle.dump(samples, open(plot_out + 'samples_'+at+'.p', 'wb'))\n",
    "    w_aa_mean_curr = np.mean(samples)\n",
    "    w_aa_dist_curr_hdi_lower  = np.percentile(samples, 2.5, axis=0)\n",
    "    w_aa_dist_curr_hdi_upper = np.percentile(samples, 97.5, axis=0)\n",
    "    err_low = -w_aa_dist_curr_hdi_lower + w_aa_mean_curr\n",
    "    err_high = w_aa_dist_curr_hdi_upper - w_aa_mean_curr\n",
    "    \n",
    "    need_at_to_errs_tup[at] = (err_low, err_high)\n",
    "    \n",
    "    pickle.dump(need_at_to_errs_tup, open(plot_out + 'need_at_to_errs_tup.p', 'wb'))\n",
    "\n",
    "'''\n",
    "need_at_to_errs_tup = pickle.load(open(plot_out + 'need_at_to_errs_tup.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9451409112173671, 3.466066972823714e-08)\n",
      "16\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is the differene in OD, linearly scaled to the wild type +/- AT case.\n",
    "\n",
    "dic_in, err_list_1_old, err_list_2_old, err_list_1_new, err_list_2_new  = get_all_grs(t1=2, t2=14)\n",
    "\n",
    "el_width = 1\n",
    "alpha=1\n",
    "ms=10\n",
    "\n",
    "plt.figure(figsize=(2, 2))\n",
    "x = list(dic_in.values())\n",
    "y = [df_muts.loc[df_muts.muts == v].yobs_from_wt.values[0] for v in dic_in.keys()]\n",
    "\n",
    "y_err = [df_muts.loc[df_muts.muts == v].yobs_errors.values[0] for v in dic_in.keys()]\n",
    "\n",
    "# split y_errors\n",
    "y_err_low = [float(v[0]) if str(v) != 'nan' else 0 for v in y_err]\n",
    "y_err_high = [float(v[1]) if str(v) != 'nan' else 0 for v in y_err]\n",
    "\n",
    "\n",
    "# add v5l and A66F errors, get from mcs df_percentile\n",
    "df_mcs = pd.read_csv('/Users/davidding/Dropbox (HMS)/parESingleLibrary/ex51_set_up_additional_mutants/illumina/data/bayes_o2_2009/log2/doubles_ex47_l/df_percentiles_diff_w_aa_m_178_mcsAT.csv')\n",
    "v5l_r = df_mcs.loc[df_mcs.aa_mut == 'V5L']\n",
    "v5l_err_low = v5l_r['2.5%'] - v5l_r.mean_fit\n",
    "v5l_err_high = v5l_r['97.5%'] - v5l_r.mean_fit\n",
    "\n",
    "y_err_low[-4] = v5l_err_low.values[0]\n",
    "y_err_high[-4] = v5l_err_high.values[0]\n",
    "\n",
    "a66f_r = df_mcs.loc[df_mcs.aa_mut == 'A66F']\n",
    "a66f_err_low = a66f_r['2.5%'] - a66f_r.mean_fit\n",
    "a66f_err_high = a66f_r['97.5%'] - a66f_r.mean_fit\n",
    "\n",
    "y_err_low[-3] = a66f_err_low.values[0]\n",
    "y_err_high[-3] = a66f_err_high.values[0]\n",
    "\n",
    "\n",
    "# get the synonyous 95% HDI's\n",
    "y_err_low[0] = need_at_to_errs_tup['G62L'][0]\n",
    "y_err_high[0] = need_at_to_errs_tup['G62L'][1]\n",
    "\n",
    "y_err_low[1] = need_at_to_errs_tup['W59T'][0]\n",
    "y_err_high[1] = need_at_to_errs_tup['W59T'][1]\n",
    "\n",
    "y_err_low[-6] = need_at_to_errs_tup['F73K'][0]\n",
    "y_err_high[-6] = need_at_to_errs_tup['F73K'][1]\n",
    "\n",
    "y_err_low[-5] = need_at_to_errs_tup['K63L'][0]\n",
    "y_err_high[-5] = need_at_to_errs_tup['K63L'][1]\n",
    "\n",
    "# x error as 2 * std\n",
    "x_err = 2*np.array([v for v in sample_to_std_1_new.values()])\n",
    "\n",
    "plt.errorbar(\n",
    "    x,y, \n",
    "    yerr=[-np.array(y_err_low), y_err_high], \n",
    "    xerr=[x_err, x_err],\n",
    "    alpha=alpha, elinewidth=el_width, fmt=\".\", ms=ms,\n",
    "    color='black'\n",
    ")\n",
    "\n",
    "plt.plot(np.unique(x), np.poly1d(np.polyfit(x, y, 1))(np.unique(x)), \n",
    "         color='red', alpha=0.2)\n",
    "\n",
    "plt.xticks([0,0.5,1], size=8)\n",
    "plt.yticks(size=8)\n",
    "\n",
    "\n",
    "print(pearsonr(x,y))\n",
    "print(len(x))\n",
    "#plt.scatter(x,y)\n",
    "plt.savefig(plot_out + 'linear_scaled_gr_diff.svg', format='svg')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
